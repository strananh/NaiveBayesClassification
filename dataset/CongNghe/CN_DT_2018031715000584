Còn nhớ vào tháng 1/2018, ông chủ Facebook là Mark Zuckerberg từng đưa ra lời khẳng định 99% thông tin trên Facebook là thật, thế nhưng trên thực tế trong khoảng hơn 1 năm trở lại đây, mạng xã hội này liên tục bị chỉ trích vì gặp phải những vấn đề liên quan tới kiểm duyệt nội dung như thông tin giả, thông tin xấu, độc hại,... Cách đây ít hôm, NBC News vừa tuyên bố "tẩy chay" Facebook và ngừng chia sẻ các nội dung của họ lên mạng này. Người đứng đầu của đài truyền hình Mỹ thậm chí gọi Facebook là "Fakebook" (Fake: làm giả) một cách đầy châm chọc. Và mới đây, Facebook lại bị dính vào một vấn đề nóng khác khi vô tình đưa ra gợi ý các video lạm dụng trẻ em trên thanh tìm kiếm, khiến dư luận vô cùng bức xúc. Cụ thể, vào ngày 16/3, một vài người dùng đã nhập từ khóa "video of" lên thanh tìm kiếm của Facebook và vô cùng bất ngờ khi hàng loạt gợi ý được đưa ra có nội dung liên quan tới sex và lạm dụng tình dục ở trẻ em gái. Những người này đã chia sẻ hình ảnh lên công cụ Twitter, cùng lời lẽ mỉa mai. Facebook đã nhanh chóng lên tiếng trước vấn đề này. "Chúng tôi vô cùng xin lỗi vì điều này", người đại diện mạng xã hội lớn nhất thế giới cho biết. "Ngay khi chúng tôi nhận được thông báo liên quan tới sự việc, chúng tôi đã gỡ bỏ chúng." Facebook lý giải rằng các dự đoán xu hướng tìm kiếm trên công cụ của họ dựa trên thói quen của người dùng. Tuy nhiên nó không phản ảnh chính xác về tất cả nội dung hiện có trên Facebook. Công ty cũng đang điều tra lý do tại sao thanh công cụ lại đưa lời gợi ý như vậy. "Chúng tôi sẽ làm việc để cải thiện chất lượng tìm kiếm", người phát ngôn của Facebook nói. "Chúng tôi không cho phép hình ảnh, video khiêu dâm và cam kết sẽ giữ chúng tránh xa môi trường trong sạch của mạng xã hội". Jonathon Morgan, người sáng lập New Knowledge - tổ chức chuyên theo dõi quá trình lan rộng của các thông tin sai sự thật trên Internet, thì cho rằng rất có thể mạng xã hội Facebook chỉ đưa ra các kết quả truy vấn gợi ý chứ không thực sự dẫn tới nội dung độc hại. "Các đề xuất tìm kiếm dựa trên truy vấn của người dùng chứ chưa chắc đã xuất phát từ một nội dung nào đó có thật", Morgan nói. "Nếu như có rất nhiều người tìm kiếm về một nội dung nào đó, có thể là một cụm từ không bình thường, trong một khoảng thời gian ngắn, hệ thống sẽ tự động quyết định rằng nên để xuất hiện cụm từ đó cho những người khác, và giả định đó là chủ đề có thực." Ông cũng cho biết thêm với tính năng này, Facebook có thể dễ dàng bị thao túng bởi các nhóm người, tổ chức muốn tuyên truyền nội dung độc hại, mà hậu quả sẽ là gây hiểu nhầm cho rất đông bộ phận người dùng khác.